{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets\"\n",
    "filename = \"original.csv\"\n",
    "\n",
    "ddos_data = pd.read_csv(\"./\" + path + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete your model name / apikey / url\n",
    "\n",
    "llm_model = \"deepseek-chat\"\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-aaaa1111bbbb2222cccc\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_data_without_label = ddos_data.drop([\" Label\"], axis=1)\n",
    "# print(ddos_data_without_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the max, min, median, mean and variance\n",
    "max_values = ddos_data_without_label.max()\n",
    "min_values = ddos_data_without_label.min()\n",
    "median_values = ddos_data_without_label.median()\n",
    "mean_values = ddos_data_without_label.mean()\n",
    "variance_values = ddos_data_without_label.var()\n",
    "\n",
    "# 将结果合并成一个新的 DataFrame\n",
    "result = pd.DataFrame({\n",
    "    'Max': max_values,\n",
    "    'Min': min_values,\n",
    "    'Median': median_values,\n",
    "    'Mean': mean_values,\n",
    "    'Variance': variance_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Knowledge Prompt\n",
    "\n",
    "know_prompt_pre = f\"Supposed that you are now an experienced network traffic data analysis expert. You need to help me analyze the data in the DDoS dataset and determine whether the data is DDoS traffic or normal traffic. Next, I will give you the maximum, minimum, median, mean, and variance of all the data under each label in the data set, which may help you make your judgment. \"\n",
    "\n",
    "know_prompt_back = \"\"\n",
    "\n",
    "for i in range(result.shape[0]):\n",
    "    know_prompt_back += f\"{result.index[i]}'s max value is{result.iloc[i].iloc[0]:0.1f}, min value is{result.iloc[i].iloc[1]:0.1f}, median value is{result.iloc[i].iloc[2]:0.1f}, mean value is{result.iloc[i].iloc[3]:0.1f}, variance value is{result.iloc[i].iloc[4]:0.1f},\"\n",
    "\n",
    "know_prompt = know_prompt_pre + know_prompt_back + \". Just remember this knowledge and you don’t need to answer me anything.\"\n",
    "\n",
    "print(know_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex pattern\n",
    "pattern = r'\\[(.*?)\\]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role reasoning inference mode\n",
    "\n",
    "# p0 = bp\n",
    "# p1 = bp + cod\n",
    "# p2 = bp + cod + cot\n",
    "# p31 = kp + bp + cod\n",
    "# p3 = kp + bp + cod + cot\n",
    "\n",
    "role_mode = 0\n",
    "\n",
    "p0, p1, p2, p31, p3 = False, False, False, False, False\n",
    "if role_mode == 0:\n",
    "    p0, p1, p2, p31, p3 = True, False, False, False, False\n",
    "elif role_mode == 1:\n",
    "    p0, p1, p2, p31, p3 = False, True, False, False, False\n",
    "elif role_mode == 2:\n",
    "    p0, p1, p2, p31, p3 = False, False, True, False, False\n",
    "elif role_mode == 3:\n",
    "    p0, p1, p2, p31, p3 = False, False, False, True, False\n",
    "elif role_mode == 4:\n",
    "    p0, p1, p2, p31, p3 = False, False, False, False, True\n",
    "\n",
    "print(p0, p1, p2, p31, p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "precount = 0\n",
    "file_path = f\"./result/deepseek_{role_mode}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增量式保存 确定上一个起始点和保存的文件位置\n",
    "startwith = 0\n",
    "if os.path.isfile(file_path):\n",
    "    test = pd.read_csv(file_path)\n",
    "    startwith = test.shape[0]\n",
    "\n",
    "print(\"startwith is: \", startwith)\n",
    "\n",
    "\n",
    "# 创建一个空的 DataFrame，保存最终的结果\n",
    "predict_df = pd.DataFrame(columns = [\"index\", \"attack\", \"benign\", \"original\"])\n",
    "\n",
    "token_prompt_pre = \"\"\n",
    "if role_mode == 0:\n",
    "    # bp\n",
    "    token_prompt_pre = f\"Next, I will give you a piece of data about network traffic information. You need to first tell me the probability of this data belonging to DDoS traffic data and normal traffic data directly and separately, and express the probability in the format of [0.xxx,0.xxx]. The characteristics of its network traffic data packets are\"\n",
    "elif role_mode == 1:\n",
    "    # bp + cod\n",
    "    token_prompt_pre = f\"Next, I will give you a piece of data about network traffic information. You need to first tell me the probability of this data belonging to DDoS traffic data and normal traffic data directly and separately, and express the probability in the format of [0.xxx,0.xxx]. The first number is the probability of DDoS traffic, and the second number is the probability of normal traffic. Both numbers are decimals between 0 and 1, and the sum of the two numbers is 1. The characteristics of its network traffic data packets are\"\n",
    "elif role_mode == 2 or role_mode == 4:\n",
    "    # bp + cod + cot\n",
    "    # kp + bp + cod + cot\n",
    "    token_prompt_pre = f\"Next, I will give you a piece of data about network traffic information. You need to first tell me the probability of this data belonging to DDoS traffic data and normal traffic data directly and separately, and express the probability in the format of [0.xxx,0.xxx]. The first number is the probability of DDoS traffic, and the second number is the probability of normal traffic. Both numbers are decimals between 0 and 1, and the sum of the two numbers is 1. Let's think step by step and explain the reasons for your judgment. The characteristics of its network traffic data packets are\"\n",
    "elif role_mode == 3:\n",
    "    token_prompt_pre = f\"Next, I will give you a piece of data about network traffic information. You need to first tell me the probability of this data belonging to DDoS traffic data and normal traffic data directly and separately, and express the probability in the format of [0.xxx,0.xxx]. The first number is the probability of DDoS traffic, and the second number is the probability of normal traffic. Both numbers are decimals between 0 and 1, and the sum of the two numbers is 1. The characteristics of its network traffic data packets are\"\n",
    "\n",
    "print(\"token_prompt_pre is: \", token_prompt_pre)\n",
    "\n",
    "# print\n",
    "for i in range(startwith, ddos_data.shape[0]):\n",
    "    token_prompt_back = \"\"\n",
    "\n",
    "    # -1的原因是去掉Label\n",
    "    netlabels = ddos_data.shape[1] - 1\n",
    "    for j in range(netlabels):\n",
    "        if j != netlabels-1:\n",
    "            token_prompt_back += f\"{ddos_data.columns[j]}:{ddos_data.iloc[i].iloc[j]},\"\n",
    "        else:\n",
    "            token_prompt_back += f\"{ddos_data.columns[j]}:{ddos_data.iloc[i].iloc[j]}\"\n",
    "    \n",
    "    token_prompt = token_prompt_pre + token_prompt_back\n",
    "\n",
    "    # non-streaming\n",
    "    messages = []\n",
    "    if role_mode == 3 or role_mode == 4:\n",
    "        messages = [{'role': 'user', 'content': know_prompt},\n",
    "                    {'role': 'user', 'content': token_prompt}]   \n",
    "    else: \n",
    "        messages = [{'role': 'user', 'content': token_prompt}]\n",
    "\n",
    "\n",
    "    completion = client.chat.completions.create(model=llm_model, messages=messages)\n",
    "    \n",
    "    matches = re.findall(pattern, completion.choices[0].message.content)\n",
    "    if len(matches) != 0:\n",
    "        result = matches[0].split(\",\")\n",
    "\n",
    "        # print(pattern, completion.choices[0].message.content)\n",
    "    \n",
    "        if len(result) == 2:\n",
    "            print(f\"| {i} | {result[0]}, {result[1]} | {matches[0]} |\")\n",
    "            # save to dataframe\n",
    "            predict_df.loc[i] = [i, result[0], result[1], matches[0]]\n",
    "        else:\n",
    "            print(f\"| {i} | None, None | {matches} |\")\n",
    "            # save to dataframe\n",
    "            predict_df.loc[i] = [i, \"None\", \"None\", completion.choices[0].message.content]\n",
    "    else:\n",
    "        print(f\"| {i} | None, None | {matches} |\")\n",
    "        # save to dataframe\n",
    "        predict_df.loc[i] = [i, \"None\", \"None\", completion.choices[0].message.content]\n",
    "\n",
    "    # for debug\n",
    "    if i == startwith + precount - 1:\n",
    "        break\n",
    "\n",
    "print(\"----- ----- done ----- -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增量式保存：如果文件存在则追加，不存在则创建\n",
    "if not os.path.isfile(file_path):\n",
    "    predict_df.to_csv(file_path, index=False)\n",
    "else:\n",
    "    predict_df.to_csv(file_path, mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
